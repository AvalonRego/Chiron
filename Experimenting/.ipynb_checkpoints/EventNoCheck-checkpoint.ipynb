{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfc4421-f963-4877-bded-9f8a57b4cad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking 1 HDF5 files in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking HDF5 Files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 91.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "directory = \"/raven/ptmp/arego/temp/\"\n",
    "column_to_check = \"event_no\"\n",
    "datasets_to_check = [\"/hits\", \"/records\"]\n",
    "\n",
    "def check_and_delete_hdf5(file_path):\n",
    "    \"\"\"Check if an HDF5 file has the required column in datasets, delete if missing.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            for dataset in datasets_to_check:\n",
    "                if dataset in f:\n",
    "                    data = f[dataset]\n",
    "                    if not isinstance(data, h5py.Dataset):\n",
    "                        print('skip')# Check if it's a dataset\n",
    "                        continue  # Skip groups\n",
    "                    if column_to_check.encode() not in data.dtype.names:\n",
    "                        os.remove(file_path)\n",
    "                        return file_path  # Return deleted file\n",
    "                else:\n",
    "                    os.remove(file_path)  # Delete if dataset is missing\n",
    "                    return file_path\n",
    "        return None  # File is valid\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_files_parallel(files):\n",
    "    \"\"\"Process HDF5 files in parallel with a progress bar.\"\"\"\n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        with tqdm(total=len(files), desc=\"Checking HDF5 Files\") as pbar:\n",
    "            for deleted_file in pool.imap_unordered(check_and_delete_hdf5, files):\n",
    "                if deleted_file:\n",
    "                    print(f\"üóëÔ∏è Deleted: {deleted_file}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hdf_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".h5\")]\n",
    "\n",
    "    if not hdf_files:\n",
    "        print(\"No HDF5 files found.\")\n",
    "    else:\n",
    "        print(f\"üîç Checking {len(hdf_files)} HDF5 files in parallel...\")\n",
    "        process_files_parallel(hdf_files)\n",
    "        print(\"‚úÖ Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756c51b-8d06-4fbc-a87e-559b7ba42ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympus",
   "language": "python",
   "name": "olympus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
