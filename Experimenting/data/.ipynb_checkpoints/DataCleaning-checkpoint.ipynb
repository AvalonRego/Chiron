{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea296300-3c13-4f58-91db-82c35a0bd4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ananke.models.collection import Collection\n",
    "from ananke.configurations.collection import HDF5StorageConfiguration\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da62febb-f363-4e8a-a8a3-9ea1fdd5aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from ananke.models.collection import Collection\n",
    "from ananke.configurations.collection import HDF5StorageConfiguration\n",
    "import pandas as pd\n",
    "\n",
    "def check_and_delete_file(file_path, failed_files, progress_queue, total_files):\n",
    "    \"\"\"Check if record count is divisible by 10; if not, delete the file.\"\"\"\n",
    "    try:\n",
    "        with pd.HDFStore(file_path, mode='a') as store:  # 'a' mode allows modifying the file\n",
    "        # Read existing datasets\n",
    "            rec_no = store['hits']\n",
    "        if rec_no % 10 != 0:\n",
    "            os.remove(file_path)\n",
    "            result = f\"Deleted {file_path} (record count: {rec_no})\"\n",
    "        else:\n",
    "            result = f\"Kept {file_path} (record count: {rec_no})\"\n",
    "\n",
    "    except Exception as e:\n",
    "        failed_files.append(file_path)\n",
    "        os.remove(file_path)\n",
    "        result = f\"Failed to process {file_path}: {e}\"\n",
    "\n",
    "    # Update progress queue\n",
    "    progress_queue.put(1)\n",
    "    return result\n",
    "\n",
    "def update_progress_bar(progress_queue, total_files):\n",
    "    \"\"\"Process function to update the tqdm progress bar.\"\"\"\n",
    "    with tqdm(total=total_files, desc=\"Processing Files\") as pbar:\n",
    "        for _ in range(total_files):\n",
    "            progress_queue.get()  # Wait for an update\n",
    "            pbar.update(1)\n",
    "\n",
    "def process_files(path, num_workers=8):\n",
    "    \"\"\"Process all files in the given path using multiple cores with progress tracking.\"\"\"\n",
    "    files = [os.path.join(path, file) for file in os.listdir(path)]\n",
    "    files = [file for file in files if '.h5' in file]\n",
    "    files = files[:10]\n",
    "    manager = multiprocessing.Manager()\n",
    "    failed_files = manager.list()  # Shared list for failed files\n",
    "    progress_queue = manager.Queue()  # Queue for progress updates\n",
    "    #return len(files)\n",
    "    total_files = len(files)\n",
    "    #return files\n",
    "\n",
    "    # Start a separate process for progress tracking\n",
    "    progress_process = multiprocessing.Process(target=update_progress_bar, args=(progress_queue, total_files))\n",
    "    progress_process.start()\n",
    "\n",
    "    with multiprocessing.Pool(num_workers) as pool:\n",
    "        results = pool.starmap(check_and_delete_file, [(file, failed_files, progress_queue, total_files) for file in files])\n",
    "\n",
    "    # Wait for progress bar process to finish\n",
    "    progress_process.join()\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "\n",
    "    # Print results\n",
    "    for res in results:\n",
    "        print(res)\n",
    "\n",
    "    # Save failed file paths\n",
    "    if failed_files:\n",
    "        with open(\"failed_files.txt\", \"w\") as \n",
    "            f.write(\"\\n\".join(failed_files))\n",
    "        print(f\"Failed files saved to failed_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2755be50-b408-448e-8bfb-0861d825d180",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_files\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raven/u/arego/project/Experimenting/data/LargeBio/100000s\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_files' is not defined"
     ]
    }
   ],
   "source": [
    "process_files('/raven/u/arego/project/Experimenting/data/LargeBio/100000s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59cc39-c343-493d-b65f-4376f175308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files('/raven/u/arego/Project/LargeCascades/20records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318eda9-3f84-45d2-bc70-52c2c9660160",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_files('/raven/u/arego/Project/LargeCMerge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb2dd2-ce55-493e-90d5-95dd8d6349a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:  18%|█▊        | 798/4491 [02:45<23:44,  2.59it/s]  "
     ]
    }
   ],
   "source": [
    "process_files('/raven/u/arego/Project/LargeTrack/20records/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1ba756-f497-4081-a785-37cedba2ef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in x.split('\\n') if 'Kept' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76a7df3-b1dd-4f52-b9b2-edf02f0f9324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5382"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/raven/u/arego/project/Experimenting/data/LargeBio/100000s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23eb52-1a4d-4c5e-875e-ac2fa3ebced1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympus",
   "language": "python",
   "name": "olympus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
